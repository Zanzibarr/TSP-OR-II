A \textit{metaheuristic} is an abstact approach that can be applied to a range of problems, which can then be specialized. In our case, our metaheuristic algorithms use more than one heuristic in order to guide the search processs to efficiently explore the search space.

We explore two metaheuristic algorithm, which both unlock a greater search space compared to the aforementioned heuristic methods by allowing "bad moves" to escape a locally optimal solution.

\section{Tabu Search}
The \textit{tabu search} algorithm \cite{Glover1990} is based on the idea of allowing the 2-opt algorithm to perform swaps that still are the best ones, but not necessarily swaps that improve the cost of the solution. Once we find a local optima, the tabu search algorithm will keep searching, moving away from that locally optimal solution hoping to find a new one with a lower cost, whereas the 2-opt algorithm would stop.

If we allowed a bad move, at the next iteration the best move found by the 2-opt procedure would revert it, since that would be the only swap that lowers the cost. To prevent this, we need to keep track of those bad moves and prevent them from being reverted, marking them as \textit{tabu moves}, hence the name of the algorithm.

\subsection{Storing a tabu move}

A tabu move is intended as the worsening move that has been done in a previous round, and it basically consists on the 2 edges, or equivalently the 4 nodes, that were considered in the swap.

To store the tabu move we have more options on what to mark as a tabu move:

\begin{enumerate}
    \item one of the nodes (fix the two edges connected to that node)
    \item both nodes (fix all four edges in the swap)
    \item one or more edges
\end{enumerate}

Marking one or both nodes as tabu moves would restrict our area of search, since after a few tabu moves, lots of edges cannot be changed, so we opted to mark as a tabu move the two edges $(p_{i},p_{i+1})$ and $(p_{j}, p_{j+1})$.

\subsection{The tabu list}

The tabu list is intended as the list of tabu moves that 2-opt will need to consult to see whether a move is admitted or not. Once the tabu list is filled up, the oldest tabu move will be removed to let the one to be saved.

An important parameter of the tabu list is its size: a small size means that the algorithm is not very free to explore the search space, while a big size means that the algorithm will worsen the solution too much, possibly preventing it to ever find a better solution. This can also be intepreted as setting its memory: a small tabu list will forget earlier tabu moves, while a big tabu list will have a longer memory.

The size (or memory) of the tabu list will hereby be referred as the its \textit{tenure}. We built the tabu list as a fixed length array, where we stored each tabu move together with a counter which increases at each new tabu move. We used the counter to see if a move is still a tabu move or not: by comparing the current counter with the one stored along the move, we can check how many iterations has passed and if more iterations than the tenure has occurred, that moves is no longer a tabu move.

We tried out two ways of checking the tenure:

\begin{enumerate}
    \item \textit{static approach}: a move in the list is no longer a tabu move if
    $$\text{counter}-\text{counter(move)} < \text{tenure}$$
    where $\text{counter(move)}$ is the counter stored along the move in the tabu list.
    \item \textit{dynamic approach}: a move in the list is no longer a tabu move if
    $$\text{counter}-\text{counter(move)} < f(\text{tenure}, \text{counter})$$
    where $f(\text{tenure},\text{counter})\coloneq A\cdot\sin(\text{counter}\cdot B) + \text{tenure}$, and $A$, $B$ are parameters specified by the user (referred as variable\_tenure and variability\_frequency).
\end{enumerate}

Here are shown two graphs, plotting the iteration counter and the cost of the solution the algorithm finds itself at:

TODO: Plot cost of tabu.

The dinamic approach performs better for a few reasons:

\begin{enumerate}
    \item it lowers the risk of remaining stuck for many iterations: when we reach a local optimum, with the dynamic approach the algorithm will start to forget some moves in a few iterations and will escape from that situation;
    \item it allows for a more dynamic exploration of the search space: the dynamic approach allows the algorithm to "forget" something to look for a better solution in the search space, but then remember it later if that leads to nothing.
\end{enumerate}

\subsection{Pseudocode}

\begin{algorithm}
    \caption{TSP tabu search algorithm}
    \hspace*{\algorithmicindent} \textbf{Input} undirected complete graph $G=(V,E)$, cost function $c:E\rightarrow\mathbb{R}$, starting node $s\in V$\\
    \hspace*{\algorithmicindent} \textbf{Output} Hamiltonian cycle of $G$ expressed as sequence of nodes visited, cost of cycle\\
    \begin{algorithmic}
        
        \State $\mbox{cycle}, \mbox{cost} \gets$ result of greedy algorithm on $s$ and $V$

        \While{timelimit not exceeded}
            \State $(i, j)\gets$ tabu move to be applied on cycle
            \State add $(i,j)$ to tabu list
            \State $\mbox{cost}\gets\mbox{cost}-(c(p_i,p_{i+1})+c(p_j,p_{j+1}))+(c(p_i,p_{j})+c(p_{i+1},p_{j+1}))$
            \State reverse section of cycle between indices $i+1$ and $j$

        \EndWhile\\

        \Return cycle, cost
    \end{algorithmic}
\end{algorithm}

Where the $\mbox{find\_tabu\_swap()}$ method returns the best swap (allowing for bad moves) after checking the tabu list.

\subsection{Results analysis}

\begin{figure}[h]
    \centering
    \includegraphics*[width=.6\textwidth]{../plots/perfprof_tabu_costs.png}
    \caption*{20 instances, 600 nodes, time limit: 120s}
\end{figure}
\FloatBarrier
\begin{figure}[h]
    \centering
    \includegraphics*[width=.6\textwidth]{../plots/perfprof_tabu_times.png}
    \caption*{20 instances, 600 nodes, time limit: 120s}
\end{figure}
\FloatBarrier

As we expected, the dynamic approach yielded better results than the static approach, and even provided better solutions compared to the 2-opt procedure with the best swap policy. However, the differences between the best tabu search results and the 2-opt results is less than 1\% of the values; this small improvement appears even smaller when we consider that the latter found its best solutions in less than half the time taken by the former.

\section{Variable Neighborhood Search (VNS)}

For the tabu algorithm to work, a list of moves must be stored as tabu moves: how many moves to store? Which one works better: a static or a dynamic tenure? And in the latter, how much should the tenure vary? This set of hyperparameters should be set with procedures that are unaffordable for the scope of this thesis. We may also run into overfitting.

Another metaheuristic method that does not require hyperparameters is the \textit{Variable Neighborhood Search (VNS)} \cite{Hansen2019}, which approaches the same base idea of tabu search in a different way.

Once we are in a local minimum, if we make a 2-opt swap (as we do with the tabu search algorithm), we must save that move as a tabu move, since the next 2-opt swap will revert it. The VNS approach is to make a swap that requires more than two edges to be swapped (entering the family of k-opt), in our case a 3-opt swap. Once a 3-opt swap is performed, it is impossible for a 2-opt swap to reverse that change, since it should change 3 edges and is allowed to change only 2 of them.

In some scenarios one 3-opt swap is enough to escape the local minimum, but in other it is not and more swaps are needed, thus creating a hyperparameter. To prevent this, we used multithreading to perform different numbers of 3-opt swaps on a local minimum, then use the 2-opt algorithm to lower the cost, and choose the best among the solutions found. Another approach that can be explored in the future is using multithreading to keep the $k$ best choices among the solutions found and keep exploring them in parallel, with special attention to keep the list of parallel runs under control, avoiding exponential growth.

TODO: talk about fast vns?

\subsection{Pseudocode}

TODO: VNS pseudocode

\subsection{Results analysis}

\FloatBarrier
\begin{figure}[h]
    \centering
    \includegraphics*[width=.6\textwidth]{../plots/perfprof_met_costs_result.png}
    \caption*{20 instances, 600 nodes, time limit: 120s}
\end{figure}

TODO: plot with meta+2opt times

The VNS obtains slightly better results to the tabu search algorithm: the costs are consistently better, even if by a 1\%/2\% factor. However, we still double the time required to find the best solution compared to the 2-opt procedure.