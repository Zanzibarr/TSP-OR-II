Our project is composed of a C program implementing a number of different TSP algorithms. We chose the C language both because of its speed and of the support offered for the software used to compute exact solutions for the TSP, IBM ILOG \textit{CPLEX}.

While the main program has been written in C, some functionalities were written in Python, in particular plotting the TSP solutions and automating tests. The language was chosen due to its extensive plotting libraries and its simplicity; such features proved to be very useful to write an interface to execute the C main program.

\section{Generating the instances}

The instances used to test the algorithms have been randomly generated. The problem space is a 2D grid: $[0,10.000]\times[0,10.000]\subset\mathbb{R}^2$. Each point is generated from an i.i.d. uniform distribution of the grid defined earlier.

\section{Installing CPLEX}

CPLEX is the \textit{MIP (Mixed Integer Programming)} solver we chose for the project. It can be downloaded and installed from the IBM SkillsBuild downloads page. CPLEX comes with an app with its own UI, but for this project we will only use its C library. 

\section{Reading the solution plots}

Each solution found is accompanied by a plot showing (graphically) the solution with some info.

Here's a list of the explanation of the info showed in the plots:

\begin{enumerate}
    \item The name of the algorithm used:
    \begin{enumerate}
        \item[greedy]: Nearest Neighborg greedy algorithm
        \item[g2opt]: applying 2opt to the greedy solution
        \item[tabu]: Tabu algorithm
        \item[vns]: VNS algorithm
        \item[cplex]: CPLEX exact algorithm
    \end{enumerate}
    \item In the same line of the algorithm there might be written some parameters used:
    \begin{enumerate}
        \item[g2opt]: (f) $\rightarrow$ g2opt with first swap policy
        \item[g2opt]: (b) $\rightarrow$ g2opt with best swap policy
        \item[tabu]: int-int-double $\rightarrow$ tabu with fixed\_tenure - variable\_tenure - variability\_frequency parameters
        \item[cplex]: benders loop $\rightarrow$ using benders loop
        \item[cplex]: mipst $\rightarrow$ giving cplex a "warm" start
        \item[cplex]: ccb $\rightarrow$ using the candidate callback
        \item[cplex]: rcb $\rightarrow$ using the relaxation callback
        \item[cplex]: n/g-patch $\rightarrow$ using patching if the solution provided is disconnected
        \item[cplex]: ccb/rcb-patch $\rightarrow$ using patching inside the (respective) callbacks
    \end{enumerate}
    (each parameter will be explained in the respective section).\\
    If the algorithm exceeded the time limit or has been terminated early by the user, an asterisk (*) will be shown at the end of the first line
    \item cost: the cost of the Hamiltonian Cycle found
    \item double/double: time needed to find that solution / total computing time
\end{enumerate}

\section{Performance profiles}

To compare different algorithms we used the \textit{performance profiles} \cite{Dolan2002}, a tool for benchmarking and comparing different optimization software and algorithms. They were generated by a Python script developed by Domenico Salvagnin. In this thesis we use this tool to compare a certain perfomance metric, either the cost of the best solution found or the time taken to find such solution, for different algorithms taken from a set $\mathcal{A}$ executed on the same set of instances $\mathcal{I}$ of the same size but generated with different random seeds.

The Python script takes as input a table of the values of the performance metric $m(a,i)$ for every combination of algorithm $a\in \mathcal{A}$ and test instance $i\in \mathcal{I}$. $\forall i\in \mathcal{I}$ the script takes the best value of the metric across all algorithms $m^*(i):=\max_{a\in\mathcal{A}}\{m(a,i)\}$ and computes $m_\%(a,i)=m(a,i)/m^*(i) \ \forall a$. With these measures, $\forall i\in \mathcal{I}$ we can measure the gap between the value of $m(a,i)$ returned by the considered algorithms $a\in\mathcal{A}$ and the best value $m^*(i)$ among those as a percentage.

These values are computed for all algorithms and instances, and with these the perfomance profile is drawn. It appears as a graph with a line $\forall a\in\mathcal{A}$ formed by points where the abscissa is a value $x$ of $m_\%(a,i)$ and the ordinate is the percentage of instances $i\in\mathcal{I}$ for which $m_\%(a,i)\leq x$. Thus, this graph represents how often the considered algorithms provided the best values of the performance metric and how far away the results of the other algorithms were from the best values.