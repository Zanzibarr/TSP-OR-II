Our project is composed of a C program implementing a number of different TSP algorithms. We chose the C language both because of its speed and of the support offered for the software used to compute exact solutions for the TSP, IBM ILOG \textit{CPLEX}.

While the main program has been written in C, some functionalities were written in Python, in particular plotting the TSP solutions and automating tests. The language was chosen due to its extensive plotting libraries and its simplicity; such features proved to be very useful to write an interface to execute the C main program.

\section{Generating the instances}

The instances used to test the algorithms have been randomly generated. The problem space is a 2D grid: $[0,10.000]\times[0,10.000]\subset\mathbb{R}^2$. Each point is generated from an i.i.d. uniform distribution of the grid defined earlier.

\section{Installing CPLEX}

CPLEX is the \textit{MIP (Mixed Integer Programming)} solver we chose for the project. It can be downloaded and installed from the IBM SkillsBuild downloads page. CPLEX comes with an app with its own UI, but for this project we will only use its C library. 

\section{Performance profiles}

To compare different algorithms we used the \textit{performance profiler} \cite{Dolan2002}, a tool for benchmarking and comparing different optimization software and algorithms.

They were generated by a Python script developed by Domenico Salvagnin. In this thesis we used this tool to compare a certain performance metric, either the cost of the best solution found or the time taken to find such solution, for different algorithms taken from a set $\mathcal{A}$ executed on the same set of instances $\mathcal{I}$ of the same size but generated with different random seeds.

The Python script takes as input a table of the values of the performance metric $m(a,i)$ for every combination of algorithm $a\in \mathcal{A}$ and test instance $i\in \mathcal{I}$. $\forall i\in \mathcal{I}$ the script takes the best value of the metric across all algorithms $m^*(i)\coloneq\max_{a\in\mathcal{A}}\{m(a,i)\}$ and computes $m_\%(a,i)=m(a,i)/m^*(i) \ \forall a$. With these measures, $\forall i\in \mathcal{I}$ we can measure the gap between the value of $m(a,i)$ returned by the considered algorithms $a\in\mathcal{A}$ and the best value $m^*(i)$ among those as a percentage.

These values are computed for all algorithms and instances, and with these the performance profile is drawn. It appears as a graph with a line $\forall a\in\mathcal{A}$ formed by points where the abscissa is a value $x$ of $m_\%(a,i)$ and the ordinate is the percentage of instances $i\in\mathcal{I}$ for which $m_\%(a,i)\leq x$. Thus, this graph represents how often the considered algorithms perform within a certain percentage from the best one.